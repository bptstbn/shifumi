@article{crisp,
  title={Towards CRISP-ML (Q): a machine learning process model with quality assurance methodology},
  author={Studer, Stefan and Bui, Thanh Binh and Drescher, Christian and Hanuschkin, Alexander and Winkler, Ludwig and Peters, Steven and M{\"u}ller, Klaus-Robert},
  journal={Machine learning and knowledge extraction},
  volume={3},
  number={2},
  pages={392--413},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}



@misc{mediapipe,
  doi = {10.48550/ARXIV.2006.10214},

  url = {https://arxiv.org/abs/2006.10214},

  author = {Zhang, Fan and Bazarevsky, Valentin and Vakunov, Andrey and Tkachenka, Andrei and Sung, George and Chang, Chuo-Ling and Grundmann, Matthias},

  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},

  title = {MediaPipe Hands: On-device Real-time Hand Tracking},

  publisher = {arXiv},

  year = {2020},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{VGG16,
  doi = {10.48550/ARXIV.1409.1556},
  url = {https://arxiv.org/abs/1409.1556},
  author = {Simonyan, Karen and Zisserman, Andrew},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{robustness,
  author    = {Nathan Drenkow and
               Numair Sani and
               Ilya Shpitser and
               Mathias Unberath},
  title     = {Robustness in Deep Learning for Computer Vision: Mind the gap?},
  journal   = {CoRR},
  volume    = {abs/2112.00639},
  year      = {2021},
  url       = {https://arxiv.org/abs/2112.00639},
  eprinttype = {arXiv},
  eprint    = {2112.00639},
  timestamp = {Tue, 07 Dec 2021 12:15:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2112-00639.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{corruption,
  author={Dodge, Samuel and Karam, Lina},
  booktitle={2017 26th International Conference on Computer Communication and Networks (ICCCN)}, 
  title={A Study and Comparison of Human and Deep Learning Recognition Performance under Visual Distortions}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/ICCCN.2017.8038465}
}

@misc{metric_formulas,
  doi = {10.48550/ARXIV.2008.05756},
  url = {https://arxiv.org/abs/2008.05756},
  author = {Grandini, Margherita and Bagli, Enrico and Visani, Giorgio},
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Metrics for Multi-Class Classification: an Overview},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@incollection{AITrust,
title = {Chapter 14 - Trust in artificial intelligence for medical diagnoses},
editor = {Beth Louise Parkin},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {253},
pages = {263-282},
year = {2020},
booktitle = {Real-World Applications in Cognitive Neuroscience},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2020.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079612320300819},
author = {Georgiana Juravle and Andriana Boudouraki and Miglena Terziyska and Constantin Rezlescu},
keywords = {Trust, AI, Healthcare, Medical diagnosis, Medical decision-making},
abstract = {We present two online experiments investigating trust in artificial intelligence (AI) as a primary and secondary medical diagnosis tool and one experiment testing two methods to increase trust in AI. Participants in Experiment 1 read hypothetical scenarios of low and high-risk diseases, followed by two sequential diagnoses, and estimated their trust in the medical findings. In three between-participants groups, the first and second diagnoses were given by: human and AI, AI and human, and human and human doctors, respectively. In Experiment 2 we examined if people expected higher standards of performance from AI than human doctors, in order to trust AI treatment recommendations. In Experiment 3 we investigated the possibility to increase trust in AI diagnoses by: (i) informing our participants that the AI outperforms the human doctor, and (ii) nudging them to prefer AI diagnoses in a choice between AI and human doctors. Results indicate overall lower trust in AI, as well as for diagnoses of high-risk diseases. Participants trusted AI doctors less than humans for first diagnoses, and they were also less likely to trust a second opinion from an AI doctor for high risk diseases. Surprisingly, results highlight that people have comparable standards of performance for AI and human doctors and that trust in AI does not increase when people are told the AI outperforms the human doctor. Importantly, we find that the gap in trust between AI and human diagnoses is eliminated when people are nudged to select AI in a free-choice paradigm between human and AI diagnoses, with trust for AI diagnoses significantly increased when participants could choose their doctor. These findings isolate control over one's medical practitioner as a valid candidate for future trust-related medical diagnosis and highlight a solid potential path to smooth acceptance of AI diagnoses amongst patients.}
}
