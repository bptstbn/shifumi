{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Rock Paper Scissors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Google Colab Setup\n",
    "\n",
    "this is just all the stuff to run our code in google Colab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# uncomment when run in GoogleColab\n",
    "\n",
    "#!pip install torchmetrics\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "#import sys\n",
    "#sys.path.append('/content/gdrive/My Drive/Uni/Project Deep Learning/Shifumi_ds/myPackages')\n",
    "import pytorch_toolkit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Connect to Google drive, so I can import modules from it into my workspace\n",
    "# set this flag to True when you run this Notebook on Google Collaboratory\n",
    "USE_COLAB = False\n",
    "\n",
    "import os\n",
    "\n",
    "#@see: https://colab.research.google.com/drive/1srw_HFWQ2SMgmWIawucXfusGzrj1_U0q\n",
    "if USE_COLAB:\n",
    "    # Load the Drive helper and mount\n",
    "    from google.colab import drive\n",
    "\n",
    "    # This will prompt for authorization.\n",
    "    gdrive_mount_point = '/content/drive/'\n",
    "    drive.mount(gdrive_mount_point)\n",
    "    grive_path = os.path.join(gdrive_mount_point, \"My Drive/\")\n",
    "    print('Your Google Drive is mounted at ', grive_path)\n",
    "    COLAB_NOTEBOOKS_PATH = os.path.join(grive_path, \"Colab Notebooks/\")\n",
    "    \n",
    "    if os.path.exists(COLAB_NOTEBOOKS_PATH):    \n",
    "        # display list of files\n",
    "        #!ls '/content/drive/My Drive/Colab Notebooks/'\n",
    "\n",
    "        # append our Google Drive folder to module search \n",
    "        # **NOTE:** comment this line out if you are NOT running this notebook on Google Colab\n",
    "        import sys\n",
    "        #sys.path.append(\"/content/drive/My Drive/Colab Notebooks/\")\n",
    "        pyt_path = os.path.join(COLAB_NOTEBOOKS_PATH, 'pytorch')\n",
    "        sys.path.append(pyt_path)\n",
    "        print('You Pytorch Colab notebooks are available at ', pyt_path)\n",
    "        print('NOTE: {} is appended to sys.path!'.format(pyt_path))\n",
    "        # and test it\n",
    "        import pytorch_toolkit as pyt\n",
    "        MODEL_SAVE_DIR = os.path.join(pyt_path, 'model_states')\n",
    "    else:\n",
    "        raise IOError(\"Unable to mount Google Drive!\")\n",
    "else:\n",
    "    MODEL_SAVE_DIR = os.path.join('.','model_states')\n",
    "    \n",
    "if not os.path.exists(MODEL_SAVE_DIR):\n",
    "    os.mkdir(MODEL_SAVE_DIR)\n",
    "\n",
    "assert os.path.exists(MODEL_SAVE_DIR)\n",
    "print('MODEL_SAVE_DIR = %s' % MODEL_SAVE_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, sys, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "# tweaks for libraries\n",
    "np.set_printoptions(precision=6, linewidth=1024, suppress=True)\n",
    "plt.style.use('seaborn')\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('notebook',font_scale=1.10)\n",
    "\n",
    "# Pytorch imports\n",
    "import torch\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print('Using Pytorch version: %s. GPU %s available' % (torch.__version__, \"IS\" if gpu_available else \"is NOT\"))\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "# My helper functions for training/evaluating etc.\n",
    "import pytorch_toolkit as pytk\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED);\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    #torch.backends.cudnn.enabled = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ModelGeneration and Training\n",
    "\n",
    "### Setup\n",
    "\n",
    "Before we start with the training we want to define some global setup variables:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CLASSES = ['rock', 'paper', 'scissors']\n",
    "# the size of the images we want to feed to the model\n",
    "model_input_size= (32,32)\n",
    "batch_size= 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the already preprocessed Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data(image_paths, target_size=model_input_size):\n",
    "    \"\"\" resizes the images to a target size\"\"\"\n",
    "    images, labels = [], []\n",
    "    for image_path in image_paths:\n",
    "        image = load_img(image_path, target_size=target_size, color_mode='grayscale')\n",
    "        image = img_to_array(image)\n",
    "        label_name = image_path.split(os.path.sep) [-2]\n",
    "        label = CLASSES.index(label_name)\n",
    "        label = np.array(label).astype('int32')\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_pattern = '/Users/amling/uni/shifumi/DataEng/datasets/combined/combined/*/*.png'\n",
    "dataset_paths = [*glob.glob(str(file_pattern))]\n",
    "random.shuffle(dataset_paths)\n",
    "images, labels = get_data(dataset_paths)\n",
    "print(f\"images.shape: {images.shape} - labels.shape: {labels.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_paths[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.bincount(labels.astype('int32')), labels[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building the model\n",
    "\n",
    "The following section builds the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, activate_dropout=True, dropout_probability=0.5):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.activate_dropout = activate_dropout\n",
    "        self.dropout_probability = dropout_probability\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.dropout1 = nn.Dropout(self.dropout_probability)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.dropout2 = nn.Dropout(self.dropout_probability)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=5, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.dropout3 = nn.Dropout(self.dropout_probability)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64*2*2, 500)\n",
    "        self.dropout4 = nn.Dropout(self.dropout_probability)\n",
    "        self.fc2 = nn.Linear(500, 3)\n",
    "        self.show_shapes()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "        if self.activate_dropout:\n",
    "            x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.pool2(x)\n",
    "        if self.activate_dropout:\n",
    "            x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.pool3(x)\n",
    "        if self.activate_dropout:\n",
    "            x = self.dropout3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        if self.activate_dropout:\n",
    "            x = self.dropout4(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def show_shapes(self):\n",
    "        print(\"Layer shapes:\")\n",
    "        print(\"\\tConv1: \", self.conv1.weight.shape)\n",
    "        print(\"\\tBN1: \", self.bn1.weight.shape)\n",
    "        print(\"\\tPool1: \", self.pool1.kernel_size)\n",
    "        if self.activate_dropout:\n",
    "            print(\"\\tDropout1: \", self.dropout1.p)\n",
    "        print(\"\\tConv2: \", self.conv2.weight.shape)\n",
    "        print(\"\\tBN2: \", self.bn2.weight.shape)\n",
    "        print(\"\\tPool2: \", self.pool2.kernel_size)\n",
    "        if self.activate_dropout:\n",
    "            print(\"\\tDropout2: \", self.dropout2.p)\n",
    "        print(\"\\tConv3: \", self.conv3.weight.shape)\n",
    "        print(\"\\tBN3: \", self.bn3.weight.shape)\n",
    "        print(\"\\tPool3: \", self.pool3.kernel_size)\n",
    "        if self.activate_dropout:\n",
    "            print(\"\\tDropout3: \", self.dropout3.p)\n",
    "        print(\"\\tFlatten: \")\n",
    "        print(\"\\tFC1: \", self.fc1.weight.shape)\n",
    "        if self.activate_dropout:\n",
    "            print(\"\\tDropout4: \", self.dropout4.p)\n",
    "        print(\"\\tFC2: \", self.fc2.weight.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split dataset into train/test sets in 70:30 ration\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, \n",
    "                                                    random_state=SEED, stratify=labels)\n",
    "# split the test set into cross-val & test datasets in 80:20 rstio\n",
    "# NOTE: Andrew Ng recommends that, if possible, the test & cv datasets should be drawn\n",
    "# from the same sample\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.3, \n",
    "                                                random_state=SEED, stratify=y_test)\n",
    "\n",
    "print(f\"X_train.shape: {X_train.shape} - y_train.shape: {y_train.shape} - class dist: {np.bincount(y_train)}\\n\" +\n",
    "      f\"X_val.shape: {X_val.shape} - y_val.shape: {y_val.shape} - class dist: {np.bincount(y_val)}\\n\" +\n",
    "      f\"X_test.shape: {X_test.shape} - y_test.shape: {y_test.shape} - class dist: {np.bincount(y_test)}\") \n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "y_val = y_val.astype('float32')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define a dataset for Pytorch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class RPSDataset(Dataset):\n",
    "    def __init__(self, x, y, transforms=None):\n",
    "        self.x = x\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        x, y = self.x[ix], self.y[ix]\n",
    "        if self.transforms is not None:\n",
    "            x = self.transforms(x)\n",
    "        return x, y\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()#,\n",
    "    #transforms.RandomAffine(0, shear=0.2),         # random shear 0.2\n",
    "    #transforms.RandomAffine(0, scale=(0.8, 1.2)),  # random zoom 0.2\n",
    "    #transforms.RandomRotation(20),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "])\n",
    "    \n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()   \n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = RPSDataset(X_train, y_train, train_transforms)\n",
    "val_dataset = RPSDataset(X_val, y_val, image_transforms)\n",
    "test_dataset = RPSDataset(X_test, y_test, image_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "data_iter = iter(testloader)\n",
    "sample_images, sample_labels = next(data_iter)\n",
    "sample_images, sample_labels = sample_images.cpu().numpy(), sample_labels.cpu().numpy()\n",
    "print(f\"images.shape: {sample_images.shape} - labels.shape: {sample_labels.shape}\")\n",
    "\n",
    "#plt.figure(figsize=(5,5))\n",
    "for i in range(32):\n",
    "    plt.subplot(4, 8, i + 1)\n",
    "    image = sample_images[i]\n",
    "    #print(f\"images[{i}].shape: {image.shape} \")\n",
    "    image = image.transpose((1,2,0))\n",
    "    #print(f\" - AP: images[{i}].shape: {image.shape}\")\n",
    "    #plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "data_iter = iter(testloader)\n",
    "sample_images, sample_labels = next(data_iter)\n",
    "sample_images, sample_labels = sample_images.cpu().numpy(), sample_labels.cpu().numpy()\n",
    "print(f\"images.shape: {sample_images.shape} - labels.shape: {sample_labels.shape}\")\n",
    "\n",
    "#plt.figure(figsize=(5,5))\n",
    "for i in range(32):\n",
    "    plt.subplot(4, 8, i + 1)\n",
    "    image = sample_images[i]\n",
    "    #print(f\"images[{i}].shape: {image.shape} \")\n",
    "    image = image.transpose((1,2,0))\n",
    "    #print(f\" - AP: images[{i}].shape: {image.shape}\")\n",
    "    #plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model, loss function, and optimizer\n",
    "model = MyModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validationloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "def test_accuracy(testloader):\n",
    "    # Test the model on the test dataset\n",
    "    outcome = {}\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        class_correct = [0. for i in range(len(CLASSES))]\n",
    "        class_total = [0. for i in range(len(CLASSES))]\n",
    "        for inputs, labels in testloader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(c)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "        print(f'Accuracy of the network on the test set: {100 * correct / total}%')\n",
    "        outcome['total'] = 100 * correct / total\n",
    "        for i in range(len(CLASSES)):\n",
    "            if class_total[1]>0:\n",
    "                print(f'Accuracy of {CLASSES[i]} : {100 * class_correct[i] / class_total[i]}%')\n",
    "                outcome[CLASSES[i]] = 100 * class_correct[i] / class_total[i]\n",
    "            else:\n",
    "                print(f'Accuracy of {CLASSES[i]} : could not be measured, no test images%')\n",
    "    return outcome\n",
    "\n",
    "def train(epoches, training_data, val_data):\n",
    "    hist=[]\n",
    "    for epoch in range(epoches):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(training_data, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1} loss: {running_loss / len(trainloader)}')\n",
    "        hist.append(test_accuracy(val_data))\n",
    "    return hist\n",
    "\n",
    "\n",
    "hist = train(epoches=10, training_data= trainloader, val_data= validationloader)\n",
    "# Define the test dataloader\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print('testing against the test dataset')\n",
    "test_accuracy(testloader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('testing against the unknwon dataset')\n",
    "file_pattern_unknown_images = f'/Users/amling/uni/shifumi/DataEng/datasets/xAI-Proj-M-validation_set_pp_01_grey/*/*.png'\n",
    "dataset_paths_unknown_images = [*glob.glob(str(file_pattern_unknown_images))]\n",
    "images_unknown, labels_unknown = get_data(dataset_paths_unknown_images)\n",
    "unknown_ds = RPSDataset(images_unknown, labels_unknown, train_transforms)\n",
    "test_accuracy(DataLoader(unknown_ds, batch_size=batch_size, shuffle=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = './model_states/pytk_rock_paper_scissors_100epoches.pt'\n",
    "#model.save(MODEL_SAVE_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "\n",
    "now there comes the evaluation part"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pytorch-Smiles-Binary Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}